#!/usr/bin/env python3
"""
ä¸ºç°æœ‰æ–‡æ¡£åˆ›å»ºç¼ºå¤±çš„å‘é‡å’Œæœç´¢ç´¢å¼•
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.core.database import get_db_context
from app.models.document import Document
from app.services.document_processor import DocumentProcessor
from app.services.vector_store import VectorStore


def fix_document_indices():
    """ä¸ºç¼ºå¤±ç´¢å¼•çš„æ–‡æ¡£åˆ›å»ºç´¢å¼•"""
    print("ğŸ”§ å¼€å§‹ä¿®å¤æ–‡æ¡£ç´¢å¼•...")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–æœåŠ¡
        print("ğŸ“¦ åˆå§‹åŒ–æœåŠ¡...")
        document_processor = DocumentProcessor()
        vector_store = VectorStore()
        
        with get_db_context() as db:
            # æŸ¥è¯¢æ‰€æœ‰æœªç´¢å¼•çš„æ–‡æ¡£
            unindexed_docs = db.query(Document).filter(
                (Document.vector_indexed == False) | (Document.search_indexed == False)
            ).all()
            
            if not unindexed_docs:
                print("âœ… æ‰€æœ‰æ–‡æ¡£éƒ½å·²ç»å»ºç«‹ç´¢å¼•ï¼")
                return True
            
            print(f"\nğŸ“Š æ‰¾åˆ° {len(unindexed_docs)} ä¸ªéœ€è¦å»ºç«‹ç´¢å¼•çš„æ–‡æ¡£")
            print()
            
            success_count = 0
            failed_count = 0
            
            for doc in unindexed_docs:
                print(f"ğŸ“„ å¤„ç†æ–‡æ¡£ {doc.id}: {doc.title}")
                print(f"   æ–‡ä»¶: {doc.filename}")
                print(f"   å‘é‡ç´¢å¼•: {'âœ…' if doc.vector_indexed else 'âŒ'}")
                print(f"   æœç´¢ç´¢å¼•: {'âœ…' if doc.search_indexed else 'âŒ'}")
                
                try:
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    file_path = Path(doc.file_path)
                    if not file_path.exists():
                        print(f"   âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {doc.file_path}")
                        failed_count += 1
                        continue
                    
                    # é‡æ–°å¤„ç†æ–‡æ¡£
                    processed_doc = document_processor.process_file(str(file_path))
                    metadata = processed_doc.get('metadata', {})
                    
                    # åˆ›å»ºå‘é‡ç´¢å¼•ï¼ˆåŒæ—¶æ”¯æŒæœç´¢åŠŸèƒ½ï¼‰
                    if not doc.vector_indexed or not doc.search_indexed:
                        print("   ğŸ”„ åˆ›å»ºå‘é‡ç´¢å¼•ï¼ˆåŒ…å«æœç´¢åŠŸèƒ½ï¼‰...")
                        vector_success = vector_store.add_document(
                            document_id=doc.id,
                            chunks=processed_doc.get('chunks', []),
                            metadata=metadata,
                        )
                        if vector_success:
                            doc.vector_indexed = True
                            doc.search_indexed = True
                            print("   âœ… å‘é‡å’Œæœç´¢ç´¢å¼•åˆ›å»ºæˆåŠŸ")
                        else:
                            print("   âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥")
                    
                    # æäº¤æ›´æ”¹
                    db.commit()
                    
                    if doc.vector_indexed and doc.search_indexed:
                        success_count += 1
                        print("   âœ… æ–‡æ¡£ç´¢å¼•å®Œæˆ")
                    else:
                        failed_count += 1
                        print("   âš ï¸  éƒ¨åˆ†ç´¢å¼•åˆ›å»ºå¤±è´¥")
                    
                except Exception as e:
                    print(f"   âŒ å¤„ç†å¤±è´¥: {str(e)}")
                    failed_count += 1
                    db.rollback()
                
                print()
            
            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            print("=" * 60)
            print(f"ğŸ“ˆ ç´¢å¼•ä¿®å¤å®Œæˆï¼")
            print(f"   æˆåŠŸ: {success_count} ä¸ªæ–‡æ¡£")
            print(f"   å¤±è´¥: {failed_count} ä¸ªæ–‡æ¡£")
            
            # æ˜¾ç¤ºå½“å‰ç´¢å¼•çŠ¶æ€
            total_docs = db.query(Document).count()
            vector_indexed = db.query(Document).filter(Document.vector_indexed == True).count()
            search_indexed = db.query(Document).filter(Document.search_indexed == True).count()
            
            print(f"\nğŸ“Š å½“å‰ç´¢å¼•çŠ¶æ€:")
            print(f"   æ€»æ–‡æ¡£æ•°: {total_docs}")
            print(f"   å‘é‡ç´¢å¼•: {vector_indexed}/{total_docs} ({vector_indexed*100//total_docs if total_docs > 0 else 0}%)")
            print(f"   æœç´¢ç´¢å¼•: {search_indexed}/{total_docs} ({search_indexed*100//total_docs if total_docs > 0 else 0}%)")
            
            return failed_count == 0
            
    except Exception as e:
        print(f"âŒ ä¿®å¤ç´¢å¼•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ–‡æ¡£ç´¢å¼•ä¿®å¤å·¥å…·")
    print()
    
    if fix_document_indices():
        print("\nâœ… ç´¢å¼•ä¿®å¤å®Œæˆ!")
        sys.exit(0)
    else:
        print("\nâš ï¸  ç´¢å¼•ä¿®å¤å®Œæˆï¼Œä½†æœ‰éƒ¨åˆ†æ–‡æ¡£å¤±è´¥")
        sys.exit(1)


if __name__ == "__main__":
    main()

